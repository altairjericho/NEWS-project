{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.layers import ZeroPadding3D, Conv3D, MaxPooling3D\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16492708217666113544\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2670198784\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 6312969162566649163\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 780, pci bus id: 0000:03:00.0, compute capability: 3.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/ML-drive/scanner-ml/Artem/share/Valerio/\"\n",
    "class_names = ['C100keV','TestSample']\n",
    "n_pols = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, name_dir='TestSample', n_pols=8):\n",
    "    \n",
    "    img_ind = []\n",
    "    path = path+name_dir+\"/crops/\"\n",
    "    img_names = os.listdir(path)\n",
    "    for name in img_names:\n",
    "        img_ind.append(re.split('[_.]',name))\n",
    "    img_ind = pd.DataFrame(np.array(img_ind),columns=['ViewID','gr','GrainID','pol','Polarization','cl','ClusterID','csv'])\n",
    "    img_ind = img_ind.drop(['csv'],axis=1).sort_values(['ViewID','GrainID','Polarization'])\n",
    "    for view in np.unique(img_ind['ViewID']):\n",
    "        view_imgs = img_ind[ img_ind['ViewID']==view ]\n",
    "        for grain in np.unique(view_imgs['GrainID']):\n",
    "            grain_imgs = view_imgs[ view_imgs['GrainID']==grain ]\n",
    "            if grain_imgs.shape[0]!=8:\n",
    "                img_ind = img_ind.drop(grain_imgs.index)\n",
    "    img_names = []\n",
    "    for name in img_ind.values:\n",
    "        img_names.append('_'.join(name)+'.csv')\n",
    "    \n",
    "    i=0\n",
    "    im_array = []\n",
    "    for name in img_names:\n",
    "        if i==0 : tmp_im = []\n",
    "        tmp_im.append(pd.read_csv(path+name, header=None).drop(31, axis=1).values)\n",
    "        i+=1\n",
    "        if i==n_pols:\n",
    "            im_array.append(np.array(tmp_im).T)\n",
    "            i=0\n",
    "    return np.array(im_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 19703\n",
      "number of test examples = 3478\n",
      "X_train shape: (19703, 31, 31, 8)\n",
      "Y_train shape: (19703, 1)\n",
      "X_test shape: (3478, 31, 31, 8)\n",
      "Y_test shape: (3478, 1)\n",
      "CPU times: user 7min 32s, sys: 3.25 s, total: 7min 35s\n",
      "Wall time: 7min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_sign = load_images(path, 'C100keV')\n",
    "y_sign = np.ones((X_sign.shape[0],1))\n",
    "X_noise = load_images(path, 'TestSample')\n",
    "y_noise = np.zeros((X_noise.shape[0],1))\n",
    "\n",
    "X = np.vstack((X_sign, X_noise))\n",
    "y = np.vstack((y_sign, y_noise))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.15, stratify=y)\n",
    "\n",
    "# Normalize image vectors (????)\n",
    "#X_train = X_train_orig/255.\n",
    "#X_test = X_test_orig/255.\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified 3D CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_3d_train shape: (19703, 31, 31, 8, 1)\n",
      "Y_train shape: (19703, 1)\n",
      "X_3d_test shape: (3478, 31, 31, 8, 1)\n",
      "Y_test shape: (3478, 1)\n",
      "CPU times: user 2.93 s, sys: 343 ms, total: 3.27 s\n",
      "Wall time: 3.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_ddd_train = np.array([X_train.T]).T\n",
    "X_ddd_test = np.array([X_test.T]).T\n",
    "\n",
    "print (\"X_3d_train shape: \" + str(X_ddd_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_3d_test shape: \" + str(X_ddd_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DDD_model(input_shape=(31,31,8,1), classes=2):\n",
    "    \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = ZeroPadding3D()(X_input)\n",
    "    X = Conv3D(64, 3, name='conv1')(X)\n",
    "    #X = BatchNormalization(name='batch1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling3D(name='pool1')(X)\n",
    "    print('conv1\\t',X.get_shape())\n",
    "    \n",
    "    X = Conv3D(128, 3, name='conv2')(X)\n",
    "    #X = BatchNormalization(name='batch2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling3D(name='pool2')(X)\n",
    "    print('conv2\\t',X.get_shape())\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "    if classes != 2 : print('oh no, too many classes, change the model output to softmax!')\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='3D_CNN_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\t (?, 15, 15, 4, 64)\n",
      "conv2\t (?, 6, 6, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "ddd_model = DDD_model(input_shape=(31,31,8,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd_model.compile(optimizer='nadam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16747 samples, validate on 2956 samples\n",
      "Epoch 1/3\n",
      "16747/16747 [==============================] - 21s 1ms/step - loss: 4.9568 - acc: 0.6843 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 2/3\n",
      "16747/16747 [==============================] - 19s 1ms/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 3/3\n",
      "16747/16747 [==============================] - 19s 1ms/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ee975be48>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd_model.fit(X_ddd_train, Y_train, epochs = 3, batch_size = 128, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3478/3478 [==============================] - 2s 592us/step\n",
      "Loss = 4.9642333353710555\n",
      "Test Accuracy = 0.6886141461637802\n"
     ]
    }
   ],
   "source": [
    "preds = ddd_model.evaluate(X_ddd_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DDD_VGG_model(input_shape=(31,31,8,1), classes=2):\n",
    "    \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Conv3D(64, 3, padding='same', activation='relu', name='conv1_1')(X_input)\n",
    "    X = Conv3D(64, 3, padding='same', name='conv1_2')(X)\n",
    "    #X = BatchNormalization(name='batch1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling3D(name='pool1')(X)\n",
    "    print('conv1\\t',X.get_shape())\n",
    "    \n",
    "    X = Conv3D(128, 3, padding='same', name='conv2')(X)\n",
    "    #X = BatchNormalization(name='batch2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling3D(name='pool2')(X)\n",
    "    print('conv2\\t',X.get_shape())\n",
    "    \n",
    "    X = Dropout(rate=0.5, name='drop_middle')(X)\n",
    "    \n",
    "    X = Conv3D(256, 3, padding='same', name='conv3')(X)\n",
    "    #X = BatchNormalization(name='batch3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling3D(name='pool3')(X)\n",
    "    print('conv3\\t',X.get_shape())\n",
    "    \n",
    "    X = Conv3D(256, 3, padding='same', name='conv4')(X)\n",
    "    #X = BatchNormalization(name='batch4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling3D(padding='same', name='pool4')(X)\n",
    "    print('conv4\\t',X.get_shape())\n",
    "    \n",
    "    X = Dropout(rate=0.5, name='drop')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "    if classes != 2 : print('oh no, too many classes, change the model output to softmax!')\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='3D_VGG_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\t (?, 15, 15, 4, 64)\n",
      "conv2\t (?, 7, 7, 2, 128)\n",
      "conv3\t (?, 3, 3, 1, 256)\n",
      "conv4\t (?, 2, 2, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "ddd_vgg_model = DDD_VGG_model(input_shape=(31,31,8,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd_vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16747 samples, validate on 2956 samples\n",
      "Epoch 1/30\n",
      "16747/16747 [==============================] - 155s 9ms/step - loss: 0.6601 - acc: 0.6832 - val_loss: 0.5957 - val_acc: 0.6962\n",
      "Epoch 2/30\n",
      "16747/16747 [==============================] - 146s 9ms/step - loss: 0.6036 - acc: 0.6875 - val_loss: 0.5733 - val_acc: 0.6962\n",
      "Epoch 3/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.5918 - acc: 0.6878 - val_loss: 0.5653 - val_acc: 0.6972\n",
      "Epoch 4/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.5512 - acc: 0.7213 - val_loss: 0.5153 - val_acc: 0.7439\n",
      "Epoch 5/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.5484 - acc: 0.7189 - val_loss: 0.5523 - val_acc: 0.6986\n",
      "Epoch 6/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.5448 - acc: 0.7159 - val_loss: 0.5034 - val_acc: 0.7476\n",
      "Epoch 7/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.5344 - acc: 0.7243 - val_loss: 0.5063 - val_acc: 0.7243\n",
      "Epoch 8/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.5292 - acc: 0.7315 - val_loss: 0.4982 - val_acc: 0.7649\n",
      "Epoch 9/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.5143 - acc: 0.7412 - val_loss: 0.4858 - val_acc: 0.7804\n",
      "Epoch 10/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4927 - acc: 0.7579 - val_loss: 0.4581 - val_acc: 0.7896\n",
      "Epoch 11/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.5165 - acc: 0.7395 - val_loss: 0.4685 - val_acc: 0.7764\n",
      "Epoch 12/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4963 - acc: 0.7610 - val_loss: 0.4560 - val_acc: 0.7764\n",
      "Epoch 13/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4799 - acc: 0.7717 - val_loss: 0.6741 - val_acc: 0.6066\n",
      "Epoch 14/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4714 - acc: 0.7773 - val_loss: 0.5251 - val_acc: 0.7361\n",
      "Epoch 15/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4714 - acc: 0.7782 - val_loss: 0.4452 - val_acc: 0.7845\n",
      "Epoch 16/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4477 - acc: 0.7892 - val_loss: 0.3977 - val_acc: 0.8234\n",
      "Epoch 17/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4394 - acc: 0.7956 - val_loss: 0.4020 - val_acc: 0.8183\n",
      "Epoch 18/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4268 - acc: 0.8021 - val_loss: 0.3723 - val_acc: 0.8319\n",
      "Epoch 19/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4578 - acc: 0.7827 - val_loss: 0.4015 - val_acc: 0.8542\n",
      "Epoch 20/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4719 - acc: 0.7720 - val_loss: 0.4640 - val_acc: 0.7744\n",
      "Epoch 21/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4332 - acc: 0.7988 - val_loss: 0.3908 - val_acc: 0.8309\n",
      "Epoch 22/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4139 - acc: 0.8153 - val_loss: 0.3906 - val_acc: 0.7889\n",
      "Epoch 23/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.3833 - acc: 0.8291 - val_loss: 0.3461 - val_acc: 0.8528\n",
      "Epoch 24/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.3554 - acc: 0.8421 - val_loss: 0.4894 - val_acc: 0.7558\n",
      "Epoch 25/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.3386 - acc: 0.8519 - val_loss: 0.3274 - val_acc: 0.8593\n",
      "Epoch 26/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.3323 - acc: 0.8548 - val_loss: 0.2824 - val_acc: 0.8860\n",
      "Epoch 27/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.3134 - acc: 0.8651 - val_loss: 0.2477 - val_acc: 0.9191\n",
      "Epoch 28/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.3049 - acc: 0.8702 - val_loss: 0.2354 - val_acc: 0.9063\n",
      "Epoch 29/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.3098 - acc: 0.8665 - val_loss: 0.2380 - val_acc: 0.9076\n",
      "Epoch 30/30\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.3231 - acc: 0.8603 - val_loss: 0.3145 - val_acc: 0.8630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ef75d4710>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd_vgg_model.fit(X_ddd_train, Y_train, epochs = 30, batch_size = 128, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3478/3478 [==============================] - 11s 3ms/step\n",
      "Loss = 0.32809947185162636\n",
      "Test Accuracy = 0.8530764805989542\n"
     ]
    }
   ],
   "source": [
    "preds = ddd_vgg_model.evaluate(X_ddd_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16747 samples, validate on 2956 samples\n",
      "Epoch 1/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2830 - acc: 0.8830 - val_loss: 0.2000 - val_acc: 0.9290\n",
      "Epoch 2/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2972 - acc: 0.8751 - val_loss: 0.2482 - val_acc: 0.9060\n",
      "Epoch 3/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2608 - acc: 0.8900 - val_loss: 0.4212 - val_acc: 0.8048\n",
      "Epoch 4/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2539 - acc: 0.8921 - val_loss: 0.2752 - val_acc: 0.8955\n",
      "Epoch 5/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2875 - acc: 0.8778 - val_loss: 0.1932 - val_acc: 0.9286\n",
      "Epoch 6/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2692 - acc: 0.8880 - val_loss: 0.2761 - val_acc: 0.8786\n",
      "Epoch 7/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2793 - acc: 0.8834 - val_loss: 0.3590 - val_acc: 0.8363\n",
      "Epoch 8/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2762 - acc: 0.8833 - val_loss: 0.3067 - val_acc: 0.8667\n",
      "Epoch 9/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2823 - acc: 0.8795 - val_loss: 0.1716 - val_acc: 0.9378\n",
      "Epoch 10/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2608 - acc: 0.8926 - val_loss: 0.2145 - val_acc: 0.9168\n",
      "Epoch 11/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2745 - acc: 0.8821 - val_loss: 0.1866 - val_acc: 0.9256\n",
      "Epoch 12/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2297 - acc: 0.9091 - val_loss: 0.1656 - val_acc: 0.9367\n",
      "Epoch 13/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2472 - acc: 0.8963 - val_loss: 0.1561 - val_acc: 0.9469\n",
      "Epoch 14/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2001 - acc: 0.9200 - val_loss: 0.1555 - val_acc: 0.9405\n",
      "Epoch 15/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2334 - acc: 0.9017 - val_loss: 0.3421 - val_acc: 0.8454\n",
      "Epoch 16/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1948 - acc: 0.9247 - val_loss: 0.1724 - val_acc: 0.9242\n",
      "Epoch 17/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2512 - acc: 0.8940 - val_loss: 0.1784 - val_acc: 0.9374\n",
      "Epoch 18/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2622 - acc: 0.8928 - val_loss: 0.1497 - val_acc: 0.9526\n",
      "Epoch 19/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2312 - acc: 0.9051 - val_loss: 0.1810 - val_acc: 0.9310\n",
      "Epoch 20/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1763 - acc: 0.9299 - val_loss: 0.1955 - val_acc: 0.9178\n",
      "Epoch 21/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.4137 - acc: 0.8090 - val_loss: 0.2691 - val_acc: 0.9076\n",
      "Epoch 22/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2520 - acc: 0.9042 - val_loss: 0.1625 - val_acc: 0.9489\n",
      "Epoch 23/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2554 - acc: 0.8968 - val_loss: 0.1524 - val_acc: 0.9476\n",
      "Epoch 24/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.3830 - acc: 0.8196 - val_loss: 0.5417 - val_acc: 0.6922\n",
      "Epoch 25/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2284 - acc: 0.9068 - val_loss: 0.1331 - val_acc: 0.9614\n",
      "Epoch 26/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2194 - acc: 0.9116 - val_loss: 0.3015 - val_acc: 0.8562\n",
      "Epoch 27/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2308 - acc: 0.9054 - val_loss: 0.1185 - val_acc: 0.9584\n",
      "Epoch 28/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2367 - acc: 0.9061 - val_loss: 0.2154 - val_acc: 0.9317\n",
      "Epoch 29/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2351 - acc: 0.9066 - val_loss: 0.1520 - val_acc: 0.9513\n",
      "Epoch 30/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2067 - acc: 0.9180 - val_loss: 0.1085 - val_acc: 0.9641\n",
      "Epoch 31/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1837 - acc: 0.9279 - val_loss: 0.1996 - val_acc: 0.9158\n",
      "Epoch 32/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1904 - acc: 0.9256 - val_loss: 0.0949 - val_acc: 0.9685\n",
      "Epoch 33/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1703 - acc: 0.9339 - val_loss: 0.1966 - val_acc: 0.9188\n",
      "Epoch 34/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1748 - acc: 0.9328 - val_loss: 0.1071 - val_acc: 0.9665\n",
      "Epoch 35/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1686 - acc: 0.9335 - val_loss: 0.2316 - val_acc: 0.8958\n",
      "Epoch 36/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1812 - acc: 0.9262 - val_loss: 0.0997 - val_acc: 0.9662\n",
      "Epoch 37/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2120 - acc: 0.9113 - val_loss: 0.1645 - val_acc: 0.9381\n",
      "Epoch 38/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1563 - acc: 0.9381 - val_loss: 0.2237 - val_acc: 0.9083\n",
      "Epoch 39/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1735 - acc: 0.9297 - val_loss: 0.1392 - val_acc: 0.9449\n",
      "Epoch 40/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1679 - acc: 0.9326 - val_loss: 0.1420 - val_acc: 0.9526\n",
      "Epoch 41/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1514 - acc: 0.9406 - val_loss: 0.1721 - val_acc: 0.9273\n",
      "Epoch 42/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1916 - acc: 0.9211 - val_loss: 0.1564 - val_acc: 0.9361\n",
      "Epoch 43/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1796 - acc: 0.9295 - val_loss: 0.1187 - val_acc: 0.9557\n",
      "Epoch 44/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1853 - acc: 0.9258 - val_loss: 0.1115 - val_acc: 0.9608\n",
      "Epoch 45/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1413 - acc: 0.9483 - val_loss: 0.0996 - val_acc: 0.9638\n",
      "Epoch 46/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2028 - acc: 0.9194 - val_loss: 0.1263 - val_acc: 0.9570\n",
      "Epoch 47/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1564 - acc: 0.9398 - val_loss: 0.1873 - val_acc: 0.9164\n",
      "Epoch 48/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1462 - acc: 0.9456 - val_loss: 0.0696 - val_acc: 0.9773\n",
      "Epoch 49/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1473 - acc: 0.9428 - val_loss: 0.5897 - val_acc: 0.7558\n",
      "Epoch 50/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1440 - acc: 0.9435 - val_loss: 0.1707 - val_acc: 0.9242\n",
      "Epoch 51/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.2232 - acc: 0.9095 - val_loss: 0.1946 - val_acc: 0.9344\n",
      "Epoch 52/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1866 - acc: 0.9273 - val_loss: 0.2695 - val_acc: 0.8843\n",
      "Epoch 53/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1603 - acc: 0.9368 - val_loss: 0.2967 - val_acc: 0.8623\n",
      "Epoch 54/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1684 - acc: 0.9343 - val_loss: 0.1245 - val_acc: 0.9516\n",
      "Epoch 55/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1765 - acc: 0.9289 - val_loss: 0.0741 - val_acc: 0.9787\n",
      "Epoch 56/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1323 - acc: 0.9504 - val_loss: 0.0967 - val_acc: 0.9672\n",
      "Epoch 57/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1556 - acc: 0.9384 - val_loss: 0.2476 - val_acc: 0.8931\n",
      "Epoch 58/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1483 - acc: 0.9436 - val_loss: 0.1848 - val_acc: 0.9212\n",
      "Epoch 59/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1857 - acc: 0.9270 - val_loss: 0.0968 - val_acc: 0.9685\n",
      "Epoch 60/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1726 - acc: 0.9304 - val_loss: 0.0915 - val_acc: 0.9662\n",
      "Epoch 61/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1266 - acc: 0.9506 - val_loss: 0.0816 - val_acc: 0.9702\n",
      "Epoch 62/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1554 - acc: 0.9398 - val_loss: 0.0732 - val_acc: 0.9787\n",
      "Epoch 63/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1648 - acc: 0.9322 - val_loss: 0.1013 - val_acc: 0.9645\n",
      "Epoch 64/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1339 - acc: 0.9513 - val_loss: 0.1146 - val_acc: 0.9621\n",
      "Epoch 65/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1652 - acc: 0.9338 - val_loss: 0.0735 - val_acc: 0.9777\n",
      "Epoch 66/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1234 - acc: 0.9530 - val_loss: 0.3469 - val_acc: 0.8518\n",
      "Epoch 67/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1368 - acc: 0.9475 - val_loss: 0.0647 - val_acc: 0.9800\n",
      "Epoch 68/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1956 - acc: 0.9184 - val_loss: 0.0942 - val_acc: 0.9645\n",
      "Epoch 69/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1216 - acc: 0.9534 - val_loss: 0.5365 - val_acc: 0.8068\n",
      "Epoch 70/70\n",
      "16747/16747 [==============================] - 143s 9ms/step - loss: 0.1868 - acc: 0.9245 - val_loss: 0.1192 - val_acc: 0.9652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f46fe17b8>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd_vgg_model.fit(X_ddd_train, Y_train, epochs = 70, batch_size = 128, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3478/3478 [==============================] - 11s 3ms/step\n",
      "Loss = 0.12498975413636684\n",
      "Test Accuracy = 0.9631972397587092\n"
     ]
    }
   ],
   "source": [
    "preds = ddd_vgg_model.evaluate(X_ddd_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG 3D with BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DDD_VGG_b_model(input_shape=(31,31,8,1), classes=2):\n",
    "    \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Conv3D(64, 3, padding='same', activation='relu', name='conv1_1')(X_input)\n",
    "    X = Conv3D(64, 3, padding='same', name='conv1_2')(X)\n",
    "    X = BatchNormalization(name='batch1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling3D(name='pool1')(X)\n",
    "    print('conv1\\t',X.get_shape())\n",
    "    \n",
    "    X = Conv3D(128, 3, padding='same', name='conv2')(X)\n",
    "    X = BatchNormalization(name='batch2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling3D(name='pool2')(X)\n",
    "    print('conv2\\t',X.get_shape())\n",
    "    \n",
    "    X = Dropout(rate=0.5, name='drop_middle')(X)\n",
    "    \n",
    "    X = Conv3D(256, 3, padding='same', name='conv3')(X)\n",
    "    X = BatchNormalization(name='batch3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling3D(name='pool3')(X)\n",
    "    print('conv3\\t',X.get_shape())\n",
    "    \n",
    "    X = Conv3D(256, 3, padding='same', name='conv4')(X)\n",
    "    X = BatchNormalization(name='batch4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling3D(padding='same', name='pool4')(X)\n",
    "    print('conv4\\t',X.get_shape())\n",
    "    \n",
    "    X = Dropout(rate=0.5, name='drop')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "    if classes != 2 : print('oh no, too many classes, change the model output to softmax!')\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='3D_VGG_b_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\t (?, 15, 15, 4, 64)\n",
      "conv2\t (?, 7, 7, 2, 128)\n",
      "conv3\t (?, 3, 3, 1, 256)\n",
      "conv4\t (?, 2, 2, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "ddd_vgg_b_model = DDD_VGG_b_model(input_shape=(31,31,8,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd_vgg_b_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16747 samples, validate on 2956 samples\n",
      "Epoch 1/30\n",
      "16747/16747 [==============================] - 164s 10ms/step - loss: 0.0720 - acc: 0.9747 - val_loss: 11.1928 - val_acc: 0.3048\n",
      "Epoch 2/30\n",
      "16747/16747 [==============================] - 158s 9ms/step - loss: 0.0679 - acc: 0.9747 - val_loss: 10.4388 - val_acc: 0.3045\n",
      "Epoch 3/30\n",
      "16747/16747 [==============================] - 155s 9ms/step - loss: 0.0558 - acc: 0.9799 - val_loss: 2.6484 - val_acc: 0.6972\n",
      "Epoch 4/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0444 - acc: 0.9852 - val_loss: 3.5573 - val_acc: 0.6972\n",
      "Epoch 5/30\n",
      "16747/16747 [==============================] - 155s 9ms/step - loss: 0.0493 - acc: 0.9818 - val_loss: 10.4297 - val_acc: 0.3221\n",
      "Epoch 6/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0519 - acc: 0.9819 - val_loss: 6.9289 - val_acc: 0.4790\n",
      "Epoch 7/30\n",
      "16747/16747 [==============================] - 155s 9ms/step - loss: 0.0440 - acc: 0.9848 - val_loss: 1.7367 - val_acc: 0.3045\n",
      "Epoch 8/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0439 - acc: 0.9849 - val_loss: 1.9475 - val_acc: 0.6979\n",
      "Epoch 9/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0453 - acc: 0.9833 - val_loss: 1.6118 - val_acc: 0.3058\n",
      "Epoch 10/30\n",
      "16747/16747 [==============================] - 155s 9ms/step - loss: 0.0400 - acc: 0.9850 - val_loss: 0.9197 - val_acc: 0.8210\n",
      "Epoch 11/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0367 - acc: 0.9868 - val_loss: 1.6166 - val_acc: 0.6823\n",
      "Epoch 12/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0399 - acc: 0.9867 - val_loss: 7.3627 - val_acc: 0.3938\n",
      "Epoch 13/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0420 - acc: 0.9853 - val_loss: 0.6797 - val_acc: 0.5254\n",
      "Epoch 14/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0339 - acc: 0.9885 - val_loss: 2.5609 - val_acc: 0.3126\n",
      "Epoch 15/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0355 - acc: 0.9884 - val_loss: 10.8337 - val_acc: 0.3048\n",
      "Epoch 16/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0320 - acc: 0.9889 - val_loss: 0.3525 - val_acc: 0.8698\n",
      "Epoch 17/30\n",
      "16747/16747 [==============================] - 155s 9ms/step - loss: 0.0328 - acc: 0.9890 - val_loss: 5.5636 - val_acc: 0.5585\n",
      "Epoch 18/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0287 - acc: 0.9904 - val_loss: 0.8426 - val_acc: 0.3214\n",
      "Epoch 19/30\n",
      "16747/16747 [==============================] - 155s 9ms/step - loss: 0.0383 - acc: 0.9882 - val_loss: 2.0328 - val_acc: 0.6658\n",
      "Epoch 20/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0327 - acc: 0.9892 - val_loss: 1.3740 - val_acc: 0.3735\n",
      "Epoch 21/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0329 - acc: 0.9882 - val_loss: 4.3151 - val_acc: 0.3048\n",
      "Epoch 22/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0294 - acc: 0.9898 - val_loss: 1.0180 - val_acc: 0.6499\n",
      "Epoch 23/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0261 - acc: 0.9913 - val_loss: 0.7191 - val_acc: 0.8183\n",
      "Epoch 24/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0307 - acc: 0.9900 - val_loss: 0.0433 - val_acc: 0.9888\n",
      "Epoch 25/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0264 - acc: 0.9919 - val_loss: 0.0786 - val_acc: 0.9783\n",
      "Epoch 26/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0309 - acc: 0.9898 - val_loss: 1.7390 - val_acc: 0.7101\n",
      "Epoch 27/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0291 - acc: 0.9901 - val_loss: 0.0653 - val_acc: 0.9855\n",
      "Epoch 28/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0268 - acc: 0.9906 - val_loss: 1.0017 - val_acc: 0.7341\n",
      "Epoch 29/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0257 - acc: 0.9920 - val_loss: 1.3805 - val_acc: 0.5663\n",
      "Epoch 30/30\n",
      "16747/16747 [==============================] - 156s 9ms/step - loss: 0.0245 - acc: 0.9918 - val_loss: 0.2818 - val_acc: 0.8867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ef57bc860>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd_vgg_b_model.fit(X_ddd_train, Y_train, epochs = 30, batch_size = 64, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3478/3478 [==============================] - 12s 3ms/step\n",
      "Loss = 0.29728871789590045\n",
      "Test Accuracy = 0.8803910293614747\n"
     ]
    }
   ],
   "source": [
    "preds = ddd_vgg_b_model.evaluate(X_ddd_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
