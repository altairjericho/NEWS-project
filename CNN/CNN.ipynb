{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scanner-ml/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16492708217666113544\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2670198784\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 6312969162566649163\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 780, pci bus id: 0000:03:00.0, compute capability: 3.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/ML-drive/scanner-ml/Artem/share/Valerio/\"\n",
    "class_names = ['C100keV','TestSample']\n",
    "n_pols = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, name_dir='TestSample', n_pols=8):\n",
    "    \n",
    "    img_ind = []\n",
    "    path = path+name_dir+\"/crops/\"\n",
    "    img_names = os.listdir(path)\n",
    "    for name in img_names:\n",
    "        img_ind.append(re.split('[_.]',name))\n",
    "    img_ind = pd.DataFrame(np.array(img_ind),columns=['ViewID','gr','GrainID','pol','Polarization','cl','ClusterID','csv'])\n",
    "    img_ind = img_ind.drop(['csv'],axis=1).sort_values(['ViewID','GrainID','Polarization'])\n",
    "    for view in np.unique(img_ind['ViewID']):\n",
    "        view_imgs = img_ind[ img_ind['ViewID']==view ]\n",
    "        for grain in np.unique(view_imgs['GrainID']):\n",
    "            grain_imgs = view_imgs[ view_imgs['GrainID']==grain ]\n",
    "            if grain_imgs.shape[0]!=8:\n",
    "                img_ind = img_ind.drop(grain_imgs.index)\n",
    "    img_names = []\n",
    "    for name in img_ind.values:\n",
    "        img_names.append('_'.join(name)+'.csv')\n",
    "    \n",
    "    i=0\n",
    "    im_array = []\n",
    "    for name in img_names:\n",
    "        if i==0 : tmp_im = []\n",
    "        tmp_im.append(pd.read_csv(path+name, header=None).drop(31, axis=1).values)\n",
    "        i+=1\n",
    "        if i==n_pols:\n",
    "            im_array.append(np.array(tmp_im).T)\n",
    "            i=0\n",
    "    return np.array(im_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 19703\n",
      "number of test examples = 3478\n",
      "X_train shape: (19703, 31, 31, 8)\n",
      "Y_train shape: (19703, 1)\n",
      "X_test shape: (3478, 31, 31, 8)\n",
      "Y_test shape: (3478, 1)\n",
      "CPU times: user 7min 32s, sys: 3.25 s, total: 7min 35s\n",
      "Wall time: 7min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_sign = load_images(path, 'C100keV')\n",
    "y_sign = np.ones((X_sign.shape[0],1))\n",
    "X_noise = load_images(path, 'TestSample')\n",
    "y_noise = np.zeros((X_noise.shape[0],1))\n",
    "\n",
    "X = np.vstack((X_sign, X_noise))\n",
    "y = np.vstack((y_sign, y_noise))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.15, stratify=y)\n",
    "\n",
    "# Normalize image vectors (????)\n",
    "#X_train = X_train_orig/255.\n",
    "#X_test = X_test_orig/255.\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sergey-like VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_model(input_shape=(31,31,8), classes=2):\n",
    "    \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X_input)\n",
    "    X = Conv2D(64, 3, activation='relu', name='conv1_1')(X)\n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Conv2D(64, 3, name='conv1_2')(X)\n",
    "    X = BatchNormalization(name='batch1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool1')(X)\n",
    "    print('conv1\\t',X.get_shape())\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Conv2D(128, 3, name='conv2')(X)\n",
    "    X = BatchNormalization(name='batch2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool2')(X)\n",
    "    print('conv2\\t',X.get_shape())\n",
    "    \n",
    "    X = Dropout(rate=0.5, name='drop_middle')(X)\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Conv2D(256, 3, name='conv3')(X)\n",
    "    X = BatchNormalization(name='batch3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool3')(X)\n",
    "    print('conv3\\t',X.get_shape())\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Conv2D(256, 3, name='conv4')(X)\n",
    "    X = BatchNormalization(name='batch4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool4')(X)\n",
    "    print('conv4\\t',X.get_shape())\n",
    "    \n",
    "    X = Dropout(rate=0.5, name='drop')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "    if classes != 2 : print('oh no, too many classes, change the model output to softmax!')\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='VGG_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\t (?, 15, 15, 64)\n",
      "conv2\t (?, 7, 7, 128)\n",
      "conv3\t (?, 3, 3, 256)\n",
      "conv4\t (?, 1, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "model = VGG_model(input_shape=(31,31,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16747 samples, validate on 2956 samples\n",
      "Epoch 1/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.1397 - acc: 0.9503 - val_loss: 1.2302 - val_acc: 0.6979\n",
      "Epoch 2/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.1003 - acc: 0.9639 - val_loss: 1.0896 - val_acc: 0.6976\n",
      "Epoch 3/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0852 - acc: 0.9698 - val_loss: 0.9155 - val_acc: 0.3914\n",
      "Epoch 4/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0763 - acc: 0.9737 - val_loss: 1.2293 - val_acc: 0.3058\n",
      "Epoch 5/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0720 - acc: 0.9758 - val_loss: 1.3417 - val_acc: 0.1722\n",
      "Epoch 6/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0625 - acc: 0.9784 - val_loss: 11.2105 - val_acc: 0.3041\n",
      "Epoch 7/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0596 - acc: 0.9803 - val_loss: 1.6595 - val_acc: 0.3051\n",
      "Epoch 8/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0622 - acc: 0.9772 - val_loss: 2.5301 - val_acc: 0.6962\n",
      "Epoch 9/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0535 - acc: 0.9810 - val_loss: 0.9804 - val_acc: 0.6519\n",
      "Epoch 10/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0500 - acc: 0.9835 - val_loss: 0.3673 - val_acc: 0.7355\n",
      "Epoch 11/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0433 - acc: 0.9847 - val_loss: 3.1475 - val_acc: 0.6962\n",
      "Epoch 12/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0437 - acc: 0.9851 - val_loss: 0.3130 - val_acc: 0.8890\n",
      "Epoch 13/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0430 - acc: 0.9856 - val_loss: 1.6851 - val_acc: 0.6965\n",
      "Epoch 14/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0477 - acc: 0.9845 - val_loss: 4.4087 - val_acc: 0.3342\n",
      "Epoch 15/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0423 - acc: 0.9856 - val_loss: 1.4297 - val_acc: 0.3048\n",
      "Epoch 16/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0409 - acc: 0.9858 - val_loss: 0.9421 - val_acc: 0.6647\n",
      "Epoch 17/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0339 - acc: 0.9891 - val_loss: 0.5513 - val_acc: 0.7344\n",
      "Epoch 18/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0365 - acc: 0.9878 - val_loss: 0.6281 - val_acc: 0.7838\n",
      "Epoch 19/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0423 - acc: 0.9872 - val_loss: 1.8440 - val_acc: 0.5656\n",
      "Epoch 20/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0313 - acc: 0.9896 - val_loss: 1.2137 - val_acc: 0.3082\n",
      "Epoch 21/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0324 - acc: 0.9884 - val_loss: 2.6634 - val_acc: 0.6965\n",
      "Epoch 22/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0355 - acc: 0.9878 - val_loss: 11.1749 - val_acc: 0.3041\n",
      "Epoch 23/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0347 - acc: 0.9876 - val_loss: 3.3561 - val_acc: 0.6972\n",
      "Epoch 24/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0344 - acc: 0.9884 - val_loss: 0.0913 - val_acc: 0.9675\n",
      "Epoch 25/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0252 - acc: 0.9917 - val_loss: 1.3177 - val_acc: 0.5359\n",
      "Epoch 26/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0298 - acc: 0.9893 - val_loss: 1.3842 - val_acc: 0.3089\n",
      "Epoch 27/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0287 - acc: 0.9896 - val_loss: 3.3959 - val_acc: 0.6962\n",
      "Epoch 28/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0268 - acc: 0.9921 - val_loss: 8.4940 - val_acc: 0.3045\n",
      "Epoch 29/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0231 - acc: 0.9921 - val_loss: 4.1205 - val_acc: 0.3051\n",
      "Epoch 30/30\n",
      "16747/16747 [==============================] - 18s 1ms/step - loss: 0.0279 - acc: 0.9898 - val_loss: 4.5053 - val_acc: 0.3045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f307383b5c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 30, batch_size = 32, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3478/3478 [==============================] - 1s 306us/step\n",
      "Loss = 4.460614165470064\n",
      "Test Accuracy = 0.31196089715296815\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model(input_shape=(31,31,8), classes=2):\n",
    "    \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X_input)\n",
    "    X = Conv2D(64, 3, name='conv1')(X)\n",
    "    #X = BatchNormalization(name='batch1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool1')(X)\n",
    "    print('conv1\\t',X.get_shape())\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "    if classes != 2 : print('oh no, too many classes, change the model output to softmax!')\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='CNN_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\t (?, 15, 15, 64)\n"
     ]
    }
   ],
   "source": [
    "cnn_model = CNN_model(input_shape=(31,31,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='nadam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16747 samples, validate on 2956 samples\n",
      "Epoch 1/30\n",
      "16747/16747 [==============================] - 4s 230us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 2/30\n",
      "16747/16747 [==============================] - 3s 204us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 3/30\n",
      "16747/16747 [==============================] - 3s 203us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 4/30\n",
      "16747/16747 [==============================] - 3s 201us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 5/30\n",
      "16747/16747 [==============================] - 3s 198us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 6/30\n",
      "16747/16747 [==============================] - 3s 201us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 7/30\n",
      "16747/16747 [==============================] - 3s 195us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 8/30\n",
      "16747/16747 [==============================] - 3s 197us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 9/30\n",
      "16747/16747 [==============================] - 3s 196us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 10/30\n",
      "16747/16747 [==============================] - 3s 198us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 11/30\n",
      "16747/16747 [==============================] - 3s 199us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 12/30\n",
      "16747/16747 [==============================] - 3s 197us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 13/30\n",
      "16747/16747 [==============================] - 3s 197us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 14/30\n",
      "16747/16747 [==============================] - 3s 196us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 15/30\n",
      "16747/16747 [==============================] - 3s 197us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 16/30\n",
      "16747/16747 [==============================] - 3s 193us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 17/30\n",
      "16747/16747 [==============================] - 3s 196us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 18/30\n",
      "16747/16747 [==============================] - 3s 193us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 19/30\n",
      "16747/16747 [==============================] - 3s 195us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 20/30\n",
      "16747/16747 [==============================] - 3s 194us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 21/30\n",
      "16747/16747 [==============================] - 3s 195us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 22/30\n",
      "16747/16747 [==============================] - 3s 195us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 23/30\n",
      "16747/16747 [==============================] - 3s 194us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 24/30\n",
      "16747/16747 [==============================] - 3s 194us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 25/30\n",
      "16747/16747 [==============================] - 3s 195us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 26/30\n",
      "16747/16747 [==============================] - 3s 194us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 27/30\n",
      "16747/16747 [==============================] - 3s 193us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 28/30\n",
      "16747/16747 [==============================] - 3s 193us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 29/30\n",
      "16747/16747 [==============================] - 3s 192us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n",
      "Epoch 30/30\n",
      "16747/16747 [==============================] - 3s 194us/step - loss: 11.0806 - acc: 0.3125 - val_loss: 11.2216 - val_acc: 0.3038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3072d13588>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_train, Y_train, epochs = 30, batch_size = 64, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3478/3478 [==============================] - 0s 131us/step\n",
      "Loss = 11.099148458554321\n",
      "Test Accuracy = 0.3113858540247335\n"
     ]
    }
   ],
   "source": [
    "preds = cnn_model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
