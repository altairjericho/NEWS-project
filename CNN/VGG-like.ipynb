{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.layers import ZeroPadding3D, Conv3D, MaxPooling3D\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16492708217666113544\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2670198784\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 6312969162566649163\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 780, pci bus id: 0000:03:00.0, compute capability: 3.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/ML-drive/scanner-ml/Artem/share/Valerio/\"\n",
    "class_names = ['C100keV','TestSample']\n",
    "n_pols = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, name_dir='TestSample', n_pols=8):\n",
    "    \n",
    "    img_ind = []\n",
    "    path = path+name_dir+\"/crops/\"\n",
    "    img_names = os.listdir(path)\n",
    "    for name in img_names:\n",
    "        img_ind.append(re.split('[_.]',name))\n",
    "    img_ind = pd.DataFrame(np.array(img_ind),columns=['ViewID','gr','GrainID','pol','Polarization','cl','ClusterID','csv'])\n",
    "    img_ind = img_ind.drop(['csv'],axis=1).sort_values(['ViewID','GrainID','Polarization'])\n",
    "    for view in np.unique(img_ind['ViewID']):\n",
    "        view_imgs = img_ind[ img_ind['ViewID']==view ]\n",
    "        for grain in np.unique(view_imgs['GrainID']):\n",
    "            grain_imgs = view_imgs[ view_imgs['GrainID']==grain ]\n",
    "            if grain_imgs.shape[0]!=8:\n",
    "                img_ind = img_ind.drop(grain_imgs.index)\n",
    "    img_names = []\n",
    "    for name in img_ind.values:\n",
    "        img_names.append('_'.join(name)+'.csv')\n",
    "    \n",
    "    i=0\n",
    "    im_array = []\n",
    "    for name in img_names:\n",
    "        if i==0 : tmp_im = []\n",
    "        tmp_im.append(pd.read_csv(path+name, header=None).drop(31, axis=1).values)\n",
    "        i+=1\n",
    "        if i==n_pols:\n",
    "            im_array.append(np.array(tmp_im).T)\n",
    "            i=0\n",
    "    return np.array(im_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 19703\n",
      "number of test examples = 3478\n",
      "X_train shape: (19703, 31, 31, 8)\n",
      "Y_train shape: (19703, 1)\n",
      "X_test shape: (3478, 31, 31, 8)\n",
      "Y_test shape: (3478, 1)\n",
      "CPU times: user 7min 32s, sys: 3.25 s, total: 7min 35s\n",
      "Wall time: 7min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_sign = load_images(path, 'C100keV')\n",
    "y_sign = np.ones((X_sign.shape[0],1))\n",
    "X_noise = load_images(path, 'TestSample')\n",
    "y_noise = np.zeros((X_noise.shape[0],1))\n",
    "\n",
    "X = np.vstack((X_sign, X_noise))\n",
    "y = np.vstack((y_sign, y_noise))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.15, stratify=y)\n",
    "\n",
    "# Normalize image vectors (????)\n",
    "#X_train = X_train_orig/255.\n",
    "#X_test = X_test_orig/255.\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sergey-like VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_model(input_shape=(31,31,8), classes=2):\n",
    "    \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X_input)\n",
    "    X = Conv2D(64, 3, activation='relu', name='conv1_1')(X)\n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Conv2D(64, 3, name='conv1_2')(X)\n",
    "    #X = BatchNormalization(name='batch1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool1')(X)\n",
    "    print('conv1\\t',X.get_shape())\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Conv2D(128, 3, name='conv2')(X)\n",
    "    #X = BatchNormalization(name='batch2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool2')(X)\n",
    "    print('conv2\\t',X.get_shape())\n",
    "    \n",
    "    X = Dropout(rate=0.5, name='drop_middle')(X)\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Conv2D(256, 3, name='conv3')(X)\n",
    "    #X = BatchNormalization(name='batch3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool3')(X)\n",
    "    print('conv3\\t',X.get_shape())\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Conv2D(256, 3, name='conv4')(X)\n",
    "    #X = BatchNormalization(name='batch4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool4')(X)\n",
    "    print('conv4\\t',X.get_shape())\n",
    "    \n",
    "    X = Dropout(rate=0.5, name='drop')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "    if classes != 2 : print('oh no, too many classes, change the model output to softmax!')\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='VGG_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\t (?, 15, 15, 64)\n",
      "conv2\t (?, 7, 7, 128)\n",
      "conv3\t (?, 3, 3, 256)\n",
      "conv4\t (?, 1, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "model = VGG_model(input_shape=(31,31,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16747 samples, validate on 2956 samples\n",
      "Epoch 1/30\n",
      "16747/16747 [==============================] - 15s 869us/step - loss: 4.9778 - acc: 0.6870 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 2/30\n",
      "16747/16747 [==============================] - 14s 807us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 3/30\n",
      "16747/16747 [==============================] - 14s 811us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 4/30\n",
      "16747/16747 [==============================] - 14s 811us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 5/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 6/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 7/30\n",
      "16747/16747 [==============================] - 14s 809us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 8/30\n",
      "16747/16747 [==============================] - 14s 811us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 9/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 10/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 11/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 12/30\n",
      "16747/16747 [==============================] - 14s 811us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 13/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 14/30\n",
      "16747/16747 [==============================] - 14s 811us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 15/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 16/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 17/30\n",
      "16747/16747 [==============================] - 14s 811us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 18/30\n",
      "16747/16747 [==============================] - 14s 809us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 19/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 20/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 21/30\n",
      "16747/16747 [==============================] - 14s 809us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 22/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 23/30\n",
      "16747/16747 [==============================] - 14s 809us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 24/30\n",
      "16747/16747 [==============================] - 14s 811us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 25/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 26/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 27/30\n",
      "16747/16747 [==============================] - 14s 811us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 28/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 29/30\n",
      "16747/16747 [==============================] - 14s 810us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n",
      "Epoch 30/30\n",
      "16747/16747 [==============================] - 14s 808us/step - loss: 4.9825 - acc: 0.6875 - val_loss: 4.8431 - val_acc: 0.6962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f44195e48>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 30, batch_size = 32, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3478/3478 [==============================] - 1s 267us/step\n",
      "Loss = 4.9642333353710555\n",
      "Test Accuracy = 0.6886141461637802\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sergey-like VGG model with BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_b_model(input_shape=(31,31,8), classes=2):\n",
    "    \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X_input)\n",
    "    X = Conv2D(64, 3, activation='relu', name='conv1_1')(X)\n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Conv2D(64, 3, name='conv1_2')(X)\n",
    "    X = BatchNormalization(name='batch1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool1')(X)\n",
    "    print('conv1\\t',X.get_shape())\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Conv2D(128, 3, name='conv2')(X)\n",
    "    X = BatchNormalization(name='batch2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool2')(X)\n",
    "    print('conv2\\t',X.get_shape())\n",
    "    \n",
    "    X = Dropout(rate=0.5, name='drop_middle')(X)\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Conv2D(256, 3, name='conv3')(X)\n",
    "    X = BatchNormalization(name='batch3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool3')(X)\n",
    "    print('conv3\\t',X.get_shape())\n",
    "    \n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Conv2D(256, 3, name='conv4')(X)\n",
    "    X = BatchNormalization(name='batch4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(name='pool4')(X)\n",
    "    print('conv4\\t',X.get_shape())\n",
    "    \n",
    "    X = Dropout(rate=0.5, name='drop')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "    if classes != 2 : print('oh no, too many classes, change the model output to softmax!')\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='VGG_b_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\t (?, 15, 15, 64)\n",
      "conv2\t (?, 7, 7, 128)\n",
      "conv3\t (?, 3, 3, 256)\n",
      "conv4\t (?, 1, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "model_b = VGG_b_model(input_shape=(31,31,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16747 samples, validate on 2956 samples\n",
      "Epoch 1/30\n",
      "16747/16747 [==============================] - 13s 773us/step - loss: 0.2887 - acc: 0.9027 - val_loss: 7.0560 - val_acc: 0.3041\n",
      "Epoch 2/30\n",
      "16747/16747 [==============================] - 10s 571us/step - loss: 0.1174 - acc: 0.9612 - val_loss: 5.3167 - val_acc: 0.3045\n",
      "Epoch 3/30\n",
      "16747/16747 [==============================] - 9s 566us/step - loss: 0.0817 - acc: 0.9735 - val_loss: 5.9269 - val_acc: 0.3048\n",
      "Epoch 4/30\n",
      "16747/16747 [==============================] - 9s 567us/step - loss: 0.0685 - acc: 0.9759 - val_loss: 3.5270 - val_acc: 0.3045\n",
      "Epoch 5/30\n",
      "16747/16747 [==============================] - 9s 567us/step - loss: 0.0579 - acc: 0.9796 - val_loss: 7.5938 - val_acc: 0.3045\n",
      "Epoch 6/30\n",
      "16747/16747 [==============================] - 10s 573us/step - loss: 0.0549 - acc: 0.9813 - val_loss: 0.8849 - val_acc: 0.6962\n",
      "Epoch 7/30\n",
      "16747/16747 [==============================] - 10s 576us/step - loss: 0.0485 - acc: 0.9829 - val_loss: 4.8909 - val_acc: 0.3045\n",
      "Epoch 8/30\n",
      "16747/16747 [==============================] - 10s 581us/step - loss: 0.0507 - acc: 0.9834 - val_loss: 0.8659 - val_acc: 0.3978\n",
      "Epoch 9/30\n",
      "16747/16747 [==============================] - 10s 570us/step - loss: 0.0417 - acc: 0.9847 - val_loss: 1.4135 - val_acc: 0.6965\n",
      "Epoch 10/30\n",
      "16747/16747 [==============================] - 10s 573us/step - loss: 0.0376 - acc: 0.9866 - val_loss: 1.2053 - val_acc: 0.2933\n",
      "Epoch 11/30\n",
      "16747/16747 [==============================] - 10s 576us/step - loss: 0.0359 - acc: 0.9886 - val_loss: 0.3578 - val_acc: 0.9347\n",
      "Epoch 12/30\n",
      "16747/16747 [==============================] - 10s 567us/step - loss: 0.0441 - acc: 0.9849 - val_loss: 11.2127 - val_acc: 0.3041\n",
      "Epoch 13/30\n",
      "16747/16747 [==============================] - 9s 567us/step - loss: 0.0286 - acc: 0.9905 - val_loss: 11.2110 - val_acc: 0.3041\n",
      "Epoch 14/30\n",
      "16747/16747 [==============================] - 10s 569us/step - loss: 0.0304 - acc: 0.9894 - val_loss: 1.4353 - val_acc: 0.3078\n",
      "Epoch 15/30\n",
      "16747/16747 [==============================] - 9s 567us/step - loss: 0.0333 - acc: 0.9882 - val_loss: 0.2638 - val_acc: 0.8654\n",
      "Epoch 16/30\n",
      "16747/16747 [==============================] - 10s 571us/step - loss: 0.0309 - acc: 0.9903 - val_loss: 6.9838 - val_acc: 0.3045\n",
      "Epoch 17/30\n",
      "16747/16747 [==============================] - 10s 581us/step - loss: 0.0354 - acc: 0.9883 - val_loss: 0.8275 - val_acc: 0.6979\n",
      "Epoch 18/30\n",
      "16747/16747 [==============================] - 10s 580us/step - loss: 0.0273 - acc: 0.9907 - val_loss: 0.4631 - val_acc: 0.7933\n",
      "Epoch 19/30\n",
      "16747/16747 [==============================] - 10s 577us/step - loss: 0.0246 - acc: 0.9923 - val_loss: 11.2104 - val_acc: 0.3045\n",
      "Epoch 20/30\n",
      "16747/16747 [==============================] - 9s 566us/step - loss: 0.0232 - acc: 0.9934 - val_loss: 0.0453 - val_acc: 0.9885\n",
      "Epoch 21/30\n",
      "16747/16747 [==============================] - 10s 575us/step - loss: 0.0242 - acc: 0.9918 - val_loss: 11.2108 - val_acc: 0.3045\n",
      "Epoch 22/30\n",
      "16747/16747 [==============================] - 10s 581us/step - loss: 0.0183 - acc: 0.9943 - val_loss: 11.2049 - val_acc: 0.3045\n",
      "Epoch 23/30\n",
      "16747/16747 [==============================] - 9s 565us/step - loss: 0.0220 - acc: 0.9928 - val_loss: 0.7317 - val_acc: 0.6965\n",
      "Epoch 24/30\n",
      "16747/16747 [==============================] - 10s 571us/step - loss: 0.0221 - acc: 0.9925 - val_loss: 11.2060 - val_acc: 0.3045\n",
      "Epoch 25/30\n",
      "16747/16747 [==============================] - 9s 565us/step - loss: 0.0176 - acc: 0.9943 - val_loss: 5.8923 - val_acc: 0.3160\n",
      "Epoch 26/30\n",
      "16747/16747 [==============================] - 9s 566us/step - loss: 0.0179 - acc: 0.9933 - val_loss: 0.5461 - val_acc: 0.6972\n",
      "Epoch 27/30\n",
      "16747/16747 [==============================] - 9s 566us/step - loss: 0.0217 - acc: 0.9927 - val_loss: 0.7720 - val_acc: 0.6962\n",
      "Epoch 28/30\n",
      "16747/16747 [==============================] - 9s 566us/step - loss: 0.0213 - acc: 0.9938 - val_loss: 0.8584 - val_acc: 0.6952\n",
      "Epoch 29/30\n",
      "16747/16747 [==============================] - 9s 565us/step - loss: 0.0262 - acc: 0.9920 - val_loss: 1.1285 - val_acc: 0.6969\n",
      "Epoch 30/30\n",
      "16747/16747 [==============================] - 9s 564us/step - loss: 0.0236 - acc: 0.9919 - val_loss: 10.5774 - val_acc: 0.3045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ef4c623c8>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit(X_train, Y_train, epochs = 30, batch_size = 256, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3478/3478 [==============================] - 1s 321us/step\n",
      "Loss = 10.488739654481789\n",
      "Test Accuracy = 0.31196089715296815\n"
     ]
    }
   ],
   "source": [
    "preds = model_b.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
